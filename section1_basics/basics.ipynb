{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb85555",
   "metadata": {},
   "source": [
    "### Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain-ollama\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5678b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a62ba9",
   "metadata": {},
   "source": [
    "### Load ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02200ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load = load_dotenv('./../.env')\n",
    "\n",
    "print(os.getenv(\"LANGSMITH_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71bedf9",
   "metadata": {},
   "source": [
    "### Interacting with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d6b841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nAlright, so I\\'m trying to figure out how to respond to the user\\'s greeting. They said, \"Hello, How are you doing?\" and then I responded with a greeting in return. Now, I need to think about how to continue this conversation.\\n\\nFirst, I should probably mirror their greeting by asking them how they\\'re doing. That makes sense because it shows politeness and engagement. So, my next step is to say something like, \"I\\'m doing well, thank you! How can I assist you today?\"\\n\\nBut wait, maybe I should consider the tone. Since they started with a friendly greeting, keeping the response warm and open would be good. I don\\'t want it to sound too formal or robotic.\\n\\nAlso, after that, I should offer help. The user might have a specific question or need assistance with something. So, adding \"How can I assist you today?\" at the end of my response makes sense because it invites them to share what they need help with.\\n\\nI should make sure there are no grammatical errors in my response. Let me read it again: \"I\\'m doing well, thank you! How can I assist you today?\" That seems correct. It\\'s concise and clear.\\n\\nIs there a better way to phrase it? Maybe, but this is straightforward and effective. It doesn\\'t overcomplicate things, which is good because the user might be looking for a quick response.\\n\\nI also wonder if adding an emoji would make it more friendly. However, since I\\'m an AI, using emojis isn\\'t appropriate, so I\\'ll stick to text only.\\n\\nIn summary, my thought process was: respond in kind by asking how they are doing, express that I\\'m doing well, and offer assistance. This approach is polite, engaging, and sets the stage for further interaction.\\n</think>\\n\\nI\\'m doing well, thank you! How can I assist you today?' additional_kwargs={} response_metadata={'model': 'deepseek-r1:8b', 'created_at': '2025-04-12T00:20:58.3866156Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4342248300, 'load_duration': 15360400, 'prompt_eval_count': 10, 'prompt_eval_duration': 30093000, 'eval_count': 385, 'eval_duration': 4295729700, 'message': Message(role='assistant', content='', images=None, tool_calls=None), 'model_name': 'deepseek-r1:8b'} id='run-6f6e8ed8-6569-476c-8872-dd11df26e721-0' usage_metadata={'input_tokens': 10, 'output_tokens': 385, 'total_tokens': 395}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm =  ChatOllama(\n",
    "    base_url = \"http://localhost:11434\",\n",
    "    model = \"deepseek-r1:8b\",\n",
    "    temperature= 0.5 ,\n",
    "    max_tokens = 1000\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"hello, How are you doing?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1661732",
   "metadata": {},
   "source": [
    "#### Structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1541fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending prompt: \"What are AI agents? What is the difference between AI, AI agents, AI workflow, automation etc\"\n",
      "\n",
      "==================================================\n",
      "--- Thinking Process ---\n",
      "==================================================\n",
      "Okay, so I'm trying to understand what AI agents are. From what I remember, AI stands for Artificial Intelligence, which is about machines being able to perform tasks that usually require human intelligence. But then there's this term \"AI agent,\" and I'm not entirely sure how it fits into all of this.\n",
      "\n",
      "I think an AI agent might be some kind of software program, right? Maybe like a robot or something that can make decisions on its own. But wait, isn't AI more about learning and adapting, while agents are more like autonomous entities? Hmm, maybe I should break it down further.\n",
      "\n",
      "So, if AI is the broader field, then AI agents must be a specific type of system within AI. Maybe they're like the ones that take inputs and process them to make decisions or actions without human intervention. For example, chatbots are AI agents because they interact with users automatically.\n",
      "\n",
      "Then there's AI workflow. I'm guessing this has to do with how AI systems handle tasks in sequence. Like, if you have a system that automates several steps, the workflow would manage the order and flow of those steps. So, an agent might be part of a larger workflow where it handles specific tasks or interactions.\n",
      "\n",
      "Automation is another term I've heard a lot. It's about making processes more efficient by reducing manual intervention. So, AI automation probably uses AI to handle repetitive or complex tasks that would otherwise require humans. That makes sense because AI can process data quickly and accurately, which is perfect for automating things.\n",
      "\n",
      "Now, trying to figure out the differences between these terms:\n",
      "\n",
      "1. **AI vs. AI Agents**: AI is the field, while AI agents are the entities within it. So, an AI agent is like a specific instance of AI that can perform tasks autonomously.\n",
      "\n",
      "2. **AI Agents vs. Workflow**: Workflow seems to be about how tasks are organized and executed. An AI workflow would involve multiple AI agents working together in a sequence to achieve a larger goal. So, the agent is part of the workflow, but the workflow is more about the structure of the process.\n",
      "\n",
      "3. **Automation vs. AI Automation**: Automation is a broader concept that includes both traditional methods (like mechanical automation) and technological ones. AI automation specifically refers to using AI technologies to automate tasks. So, it's a subset of automation that leverages AI capabilities.\n",
      "\n",
      "Wait, but I'm not sure if I got that right. Let me think again. If automation can be done without AI, then AI automation is just one type of automation. That makes sense because there are other ways to automate processes before AI became prevalent.\n",
      "\n",
      "So, putting it all together:\n",
      "\n",
      "- **AI**: The field focused on creating intelligent systems.\n",
      "- **AI Agents**: Individual entities within AI that can perform tasks and make decisions autonomously.\n",
      "- **AI Workflow**: The structured sequence of tasks or actions managed by AI, often involving multiple agents working together.\n",
      "- **Automation**: The broader concept of making processes efficient through technology, including AI automation which uses AI to handle tasks.\n",
      "\n",
      "I think I have a better grasp now. AI agents are like the actors within the AI system, while workflows manage how they interact and perform tasks. Automation is the overall efficiency improvement, with AI automation being a specific method.\n",
      "\n",
      "\n",
      "==================================================\n",
      "--- Main Response ---\n",
      "==================================================\n",
      "**Understanding AI Agents and Related Concepts**\n",
      "\n",
      "1. **Artificial Intelligence (AI)**:\n",
      "   - The field focused on creating intelligent systems that can perform tasks typically requiring human intelligence.\n",
      "\n",
      "2. **AI Agents**:\n",
      "   - Autonomous entities within AI that process inputs to make decisions or take actions without human intervention. Examples include chatbots and recommendation systems.\n",
      "\n",
      "3. **AI Workflow**:\n",
      "   - The structured sequence of tasks managed by AI, often involving multiple agents working together to achieve a larger goal. It's the organization and execution structure of tasks.\n",
      "\n",
      "4. **Automation**:\n",
      "   - The broader concept of enhancing efficiency through technology. AI automation specifically refers to using AI technologies to automate tasks, which is a subset of automation that leverages AI capabilities.\n",
      "\n",
      "**Key Differences**:\n",
      "\n",
      "- **AI vs. AI Agents**: AI is the field; AI agents are specific entities within it.\n",
      "- **AI Agents vs. Workflow**: AI agents are part of the workflow, which manages task sequences and structures.\n",
      "- **Automation vs. AI Automation**: Automation is broader, including traditional methods, while AI automation specifically uses AI technologies.\n",
      "\n",
      "In summary, AI agents are integral to AI systems, working within structured workflows to automate tasks efficiently.\n",
      "\n",
      "\n",
      "==================================================\n",
      "--- Response Metadata ---\n",
      "==================================================\n",
      "{\n",
      "    \"model\": \"deepseek-r1:8b\",\n",
      "    \"created_at\": \"2025-04-12T00:21:56.5065922Z\",\n",
      "    \"done\": true,\n",
      "    \"done_reason\": \"stop\",\n",
      "    \"total_duration\": 10322892200,\n",
      "    \"load_duration\": 15691500,\n",
      "    \"prompt_eval_count\": 23,\n",
      "    \"prompt_eval_duration\": 46744600,\n",
      "    \"eval_count\": 908,\n",
      "    \"eval_duration\": 10260013300,\n",
      "    \"message\": \"role='assistant' content='' images=None tool_calls=None\",\n",
      "    \"model_name\": \"deepseek-r1:8b\"\n",
      "}\n",
      "\n",
      "\n",
      "==================================================\n",
      "--- Usage Metadata ---\n",
      "==================================================\n",
      "{\n",
      "    \"input_tokens\": 23,\n",
      "    \"output_tokens\": 908,\n",
      "    \"total_tokens\": 931\n",
      "}\n",
      "\n",
      "\n",
      "==================================================\n",
      "--- Other Info ---\n",
      "==================================================\n",
      "{\n",
      "    \"id\": \"run-d806d147-2fc0-4327-a654-6f932650031c-0\",\n",
      "    \"additional_kwargs\": {},\n",
      "    \"type\": \"ai\"\n",
      "}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import AIMessage # Import AIMessage for type hinting (optional but good practice)\n",
    "\n",
    "# --- Initialize the LLM (same as before) ---\n",
    "llm =  ChatOllama(\n",
    "    base_url = \"http://localhost:11434\",\n",
    "    model = \"deepseek-r1:8b\",\n",
    "    temperature= 0.5\n",
    ")\n",
    "\n",
    "# --- Invoke the LLM (same as before) ---\n",
    "prompt = \"What are AI agents? What is the difference between AI, AI agents, AI workflow, automation etc\"\n",
    "print(f\"Sending prompt: \\\"{prompt}\\\"\\n\")\n",
    "response: AIMessage = llm.invoke(prompt) # Added type hint\n",
    "\n",
    "\n",
    "# --- Structure and Visualize the Output ---\n",
    "\n",
    "# 1. Extract the full content string\n",
    "full_content = response.content\n",
    "\n",
    "# 2. Separate the <think> block and the main response using regex\n",
    "think_content = \"N/A\" # Default if not found\n",
    "main_response = full_content # Default if no think block\n",
    "\n",
    "# Use regex to find the think block (dot matches newline)\n",
    "# Assuming the model *might* output <think> tags based on the original code's intent\n",
    "# If your model doesn't use <think>, this part might not find anything, which is fine.\n",
    "match = re.search(r\"<think>(.*?)</think>\", full_content, re.DOTALL)\n",
    "if match:\n",
    "    think_content = match.group(1).strip() # Get content inside tags\n",
    "    # Find the end of the </think> tag to get the main response after it\n",
    "    end_think_tag_index = match.end()\n",
    "    main_response = full_content[end_think_tag_index:].strip()\n",
    "else:\n",
    "    # If no <think> block, assume the whole content is the main response\n",
    "    # and the thinking process is not explicitly separated in the output.\n",
    "    main_response = full_content.strip()\n",
    "    think_content = \"(No <think> block found in response)\"\n",
    "\n",
    "\n",
    "# 3. Extract Metadata\n",
    "response_meta = response.response_metadata\n",
    "usage_meta = response.usage_metadata\n",
    "other_info = {\n",
    "    \"id\": response.id,\n",
    "    \"additional_kwargs\": response.additional_kwargs,\n",
    "    # Add type if needed, though it's usually clear from context\n",
    "    \"type\": response.type\n",
    "}\n",
    "\n",
    "# --- FIX: Define a default serializer function for json.dumps ---\n",
    "def default_serializer(obj):\n",
    "    \"\"\"Convert non-serializable objects to strings.\"\"\"\n",
    "    try:\n",
    "        # Let the default encoder try first\n",
    "        return json.JSONEncoder().default(obj)\n",
    "    except TypeError:\n",
    "        # If it fails, convert the object to its string representation\n",
    "        return str(obj)\n",
    "\n",
    "# 4. Print the structured output\n",
    "print(\"=\"*50)\n",
    "print(\"--- Thinking Process ---\")\n",
    "print(\"=\"*50)\n",
    "print(think_content)\n",
    "print(\"\\n\") # Add a newline for spacing\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"--- Main Response ---\")\n",
    "print(\"=\"*50)\n",
    "print(main_response)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"--- Response Metadata ---\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- FIX: Use the default serializer in json.dumps ---\n",
    "print(json.dumps(response_meta, indent=4, default=default_serializer))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"--- Usage Metadata ---\")\n",
    "print(\"=\"*50)\n",
    "# Assuming usage_meta is already JSON serializable (usually is)\n",
    "# If you get an error here too, apply the same default=default_serializer fix\n",
    "print(json.dumps(usage_meta, indent=4))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"--- Other Info ---\")\n",
    "print(\"=\"*50)\n",
    "# other_info should be serializable as constructed\n",
    "print(json.dumps(other_info, indent=4))\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
